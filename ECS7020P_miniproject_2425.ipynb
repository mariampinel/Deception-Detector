{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariampinel/Deception-Detector/blob/main/ECS7020P_miniproject_2425.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91MsGMTna_P9"
      },
      "source": [
        "# ECS7020P mini-project submission\n",
        "\n",
        "\n",
        "## What is the problem?\n",
        "\n",
        "This year's mini-project considers the problem of predicting whether a narrated story is true or not. Specifically, you will build a machine learning model that takes as an input an audio recording of **30 seconds** of duration and predicts whether the story being narrated is **true or not**.\n",
        "\n",
        "\n",
        "## Which dataset will I use?\n",
        "\n",
        "A total of 100 samples consisting of a complete audio recording, a *Language* attribute and a *Story Type* attribute have been made available for you to build your machine learning model. The audio recordings can be downloaded from:\n",
        "\n",
        "https://github.com/MLEndDatasets/Deception/tree/main/MLEndDD_stories_small\n",
        "\n",
        "A CSV file recording the *Language* attribute and *Story Type* of each audio file can be downloaded from:\n",
        "\n",
        "https://github.com/MLEndDatasets/Deception/blob/main/MLEndDD_story_attributes_small.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## What will I submit?\n",
        "\n",
        "Your submission will consist of **one single Jupyter notebook** that should include:\n",
        "\n",
        "*   **Text cells**, describing in your own words, rigorously and concisely your approach, each implemented step and the results that you obtain,\n",
        "*   **Code cells**, implementing each step,\n",
        "*   **Output cells**, i.e. the output from each code cell,\n",
        "\n",
        "Your notebook **should have the structure** outlined below. Please make sure that you **run all the cells** and that the **output cells are saved** before submission.\n",
        "\n",
        "Please save your notebook as:\n",
        "\n",
        "* ECS7020P_miniproject_2425.ipynb\n",
        "\n",
        "\n",
        "## How will my submission be evaluated?\n",
        "\n",
        "This submission is worth 16 marks. We will value:\n",
        "\n",
        "*   Conciseness in your writing.\n",
        "*   Correctness in your methodology.\n",
        "*   Correctness in your analysis and conclusions.\n",
        "*   Completeness.\n",
        "*   Originality and efforts to try something new.\n",
        "\n",
        "**The final performance of your solutions will not influence your grade**. We will grade your understanding. If you have an good understanding, you will be using the right methodology, selecting the right approaches, assessing correctly the quality of your solutions, sometimes acknowledging that despite your attempts your solutions are not good enough, and critically reflecting on your work to suggest what you could have done differently.\n",
        "\n",
        "Note that **the problem that we are intending to solve is very difficult**. Do not despair if you do not get good results, **difficulty is precisely what makes it interesting** and **worth trying**.\n",
        "\n",
        "## Show the world what you can do\n",
        "\n",
        "Why don't you use **GitHub** to manage your project? GitHub can be used as a presentation card that showcases what you have done and gives evidence of your data science skills, knowledge and experience. **Potential employers are always looking for this kind of evidence**.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwJ1w8v8hX9g"
      },
      "source": [
        "-------------------------------------- PLEASE USE THE STRUCTURE BELOW THIS LINE --------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kozfd9uehX9j"
      },
      "source": [
        "# [Your title goes here]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**:  Maria Martinez\n",
        "**Student ID**:  240990523\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "\n",
        "Describe the machine learning problem that you want to solve and explain what's interesting about it.\n",
        "\n",
        "- This year's mini-project considers the problem of predicting whether a narrated story is true or not. Specifically, you will build a machine learning model that takes as an input an audio recording of **30 seconds** of duration and predicts whether the story being narrated is **true or not**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S3n2Xt5IHJOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Factors\n",
        "  - Lie is prepared, pre-thought\n",
        "  - Take into account silent periods: 0.1s or longer\n",
        "  - Identify: vocalizations, inspirations and expirations, tongue noises, laughs and giggles, and hiccoughs.\n",
        "  - Possible measures: rate of speech (the relationship between the number of\n",
        "syllables in the statement and its overall duration) and the rate of articula-\n",
        "tion (based on the length of the speech excluding filled and unfilled\n",
        "pauses)\n",
        "  - fundamental frequency (F0) was extracted using the spectral clipping method and zero crossing analysis\n",
        "       Calculate mean, range and SD\n",
        "  - Verbal measures: 1) the number of arguments (1 =hair; 2 = age); (2) the\n",
        "total number of words; (3) the eloquency index (given by the ratio between\n",
        "number of words and number of arguments); and (4) the disfluency index\n",
        "(given by the sum of interrupted and repeated words).\n",
        "\n",
        "1.  31 male university students were asked to raise doubts in an expert in law about a picture. The subjects were required to describe the picture in three experimental conditions: telling the truth (T) and lying to a speaker when acquiescent (L1) and when suspicious (L2). The utterances were then subjected to a digitized acoustic analysis in order to measure nonverbal vocal variables\n",
        "\n",
        "**Evidence**\n",
        "  - Supported Predictors: the number of pauses {F = 4.67; p < .012) and the number of syllable. F0.\n",
        "  - Suggestion: Look at extreme values- Outliers might me tells for lies\n",
        "      - Calculate number of outliers of each sample\n",
        "      \n",
        "  - On the contrary, mean pause duration (considering filled and un-\n",
        "filled pauses separately), mean phrases and speech duration, and mean\n",
        "rate of articulation and language speed showed no significant overall ef-\n",
        "fect.\n",
        "- Calculate number of pauses. Why:\n",
        "    - The complexity of the cognitive task lies in the discrepancy between private knowledge and public statement: the liar (L) knows the truth (which he/she does not tell), but publicly tells a lie (which he/she does not believe, but has to make the H think that he/she does believe it). The cognitive conflict between the knowledge of truth and the encoded message denying (or concealing) it, as well as the need \"to disguise\" one's true beliefs, imply a saturation of the L's mental capacities making the\n",
        "task of deception all the more complex. This complexity, in fact, came to\n",
        "light in the research through the results of the experiment in the L1 condi-\n",
        "tion especially. These showed a rise in the number of shorter and more\n",
        "recurrent pauses which,\n",
        "2. There are 3 types of liars: : good liars, tense liars (more numerous in L1), and overcontrolled liars (more numerous in L2)"
      ],
      "metadata": {
        "id": "S50-e5_RHOH8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 3 Methodology\n",
        "\n",
        "Describe your methodology. Specifically, describe your training task and validation task, and how model performance is defined (i.e. accuracy, confusion matrix, etc). Any other tasks that might help you build your model should also be described here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 4 Implemented ML prediction pipelines\n",
        "\n",
        "Describe the ML prediction pipelines that you will explore. Clearly identify their input and output, stages and format of the intermediate data structures moving from one stage to the next. It's up to you to decide which stages to include in your pipeline. After providing an overview, describe in more detail each one of the stages that you have included in their corresponding subsections (i.e. 4.1 Transformation stage, 4.2 Model stage, 4.3 Ensemble stage)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "## 4.1 Transformation stage\n",
        "\n",
        "Describe any transformations, such as feature extraction. Identify input and output. Explain why you have chosen this transformation stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "## 4.2 Model stage\n",
        "\n",
        "Describe the ML model(s) that you will build. Explain why you have chosen them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dytPttlAhX9v"
      },
      "source": [
        "## 4.3 Ensemble stage\n",
        "\n",
        "Describe any ensemble approach you might have included. Explain why you have chosen them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 5 Dataset\n",
        "\n",
        "Describe the datasets that you will create to build and evaluate your models. Your datasets need to be based on our MLEnd Deception Dataset. After describing the datasets, build them here. You can explore and visualise the datasets here as well.\n",
        "\n",
        "If you are building separate training and validation datasets, do it here. Explain clearly how you are building such datasets, how you are ensuring that they serve their purpose (i.e. they are independent and consist of IID samples) and any limitations you might think of. It is always important to identify any limitations as early as possible. The scope and validity of your conclusions will depend on your ability to understand the limitations of your approach.\n",
        "\n",
        "If you are exploring different datasets, create different subsections for each dataset and give them a name (e.g. 5.1 Dataset A, 5.2 Dataset B, 5.3 Dataset 5.3) .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages\n",
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os, sys, re, pickle, glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG_wAFhzmC1l",
        "outputId": "39c3c41e-a173-4339-ee14-4e05f0b8c86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install library - make sure you have version 1.0.0.4\n",
        "%%capture\n",
        "!pip install mlend==1.0.0.4\n"
      ],
      "metadata": {
        "id": "ueJgnnH_mQRt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import library and functions\n",
        "import mlend\n",
        "from mlend import download_deception_small, deception_small_load"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQycsVll7BC-",
        "outputId": "3a7f53de-5ec8-4790-e623-b082398cd126"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download small data\n",
        "datadir = download_deception_small(save_to='MLEnd', subset={}, verbose=1, overwrite=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "QjsQciHp7TKc",
        "outputId": "4cfff80d-6a34-401c-fc55-8517a4884a41"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 100 stories (audio files) from https://github.com/MLEndDatasets/Deception\n",
            "100%|\u001b[92m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[0m|100\\100|00100.wav\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'MLEnd/deception'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read file paths\n",
        "TrainSet, TestSet, MAPs = deception_small_load(datadir_main=datadir, train_test_split=0.2, verbose=1, encode_labels=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQxEyUNK7T6f",
        "outputId": "177ed103-a028-445c-b09e-b1bf43cb5dc9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 100 found in MLEnd/deception/MLEndDD_stories_small/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TAU6bWe--_0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data: Extracted as a dictionary\n",
        "## Maps contains meaning of encoded labels\n",
        "# Length of training set\n",
        "len(TrainSet['X_paths'])\n",
        "# Length of Test set: 80 for 80% of dataset\n",
        "TrainSet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_oF5gdR9e7T",
        "outputId": "166850ce-fbd0-4258-b3f3-3032b886a441"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X_paths': ['MLEnd/deception/MLEndDD_stories_small/00001.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00007.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00014.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00019.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00023.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00027.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00041.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00048.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00051.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00054.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00057.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00060.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00061.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00066.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00072.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00081.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00082.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00084.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00098.wav',\n",
              "  'MLEnd/deception/MLEndDD_stories_small/00099.wav'],\n",
              " 'Y': array(['deceptive_story', 'true_story', 'true_story', 'deceptive_story',\n",
              "        'deceptive_story', 'deceptive_story', 'deceptive_story',\n",
              "        'true_story', 'deceptive_story', 'true_story', 'true_story',\n",
              "        'deceptive_story', 'true_story', 'true_story', 'deceptive_story',\n",
              "        'deceptive_story', 'true_story', 'true_story', 'deceptive_story',\n",
              "        'true_story'], dtype=object),\n",
              " 'Y_encoded': array([1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To read the documentation on the given functions run:\n",
        "help(download_deception_small)\n",
        "help(deception_small_load)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfJ_WAS87aoq",
        "outputId": "d07b7522-45af-4ebd-c30d-aec57915addc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function download_deception_small in module mlend.downloader:\n",
            "\n",
            "download_deception_small(save_to='../MLEnd', subset={}, verbose=1, overwrite=False, pbar_style='colab')\n",
            "    Download Deception Dataset - small size.\n",
            "    \n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    save_to: str, default ('../MLEnd')\n",
            "       - local path where you want to store the data\n",
            "         relative to `../MLEnd/deception/`).\n",
            "    \n",
            "    subset: dict, default={}\n",
            "    -  subset of data to download. {'attribute_name':list_of_values to select}\n",
            "        subset = {'Language':['English','Hindi']}, will download stories of English and Hindi langauge only \n",
            "        subset = {'Language':['English'], 'Story_type':['true_story']} will download true stories narrated in English only\n",
            "        subset = {} will download entire small dataset (100 stories)\n",
            "    \n",
            "    subset of data\n",
            "    \n",
            "    verbose: bool, (default=1)\n",
            "       - verbosity level, show progress\n",
            "    \n",
            "    overwrite: bool, default=False\n",
            "       - to avoid downloaing files, if already exist,\n",
            "       - if True, fresh copy of file will be downloaded\n",
            "    \n",
            "    pbar_style: progress bar style\n",
            "    \n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    path: path where data is saved\n",
            "    \n",
            "    \n",
            "    References\n",
            "    ----------\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    download_spoken_numerals,\n",
            "    download_london_sounds,\n",
            "    download_hums_whistles,\n",
            "    download_yummy_small,\n",
            "    download_yummy,\n",
            "    download_happiness\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> #mlend.download_deception_small\n",
            "    >>> from mlend import download_deception_small\n",
            "    >>> path = download_deception_small()\n",
            "\n",
            "Help on function deception_small_load in module mlend.processing:\n",
            "\n",
            "deception_small_load(datadir_main='../MLEnd/deception', train_test_split=None, verbose=1, encode_labels=False, warn=True)\n",
            "    Read files of Deception Dataset small.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    datadir_main (str): local path where 'MLEndDD_stories_small' directory is stored\n",
            "                  relative to `../MLEnd/deception/`).\n",
            "    train_test_split (str) or defualt=None: \n",
            "          - split type for training and testing, or no-split          \n",
            "          - 'Random' or 'random': random split woth 70-30\n",
            "          - float (e.g. 0.8) (>0 and <1)\n",
            "            random split with given fraction for training set.\n",
            "            if train_test_split = 0.8, Training set will be 80% and Testing 20%\n",
            "          - 'Benchmark_A': RESERVED FOR FUTURE VERSION\n",
            "          - if None, all the data will be in TrainSet, and none in TestSet\n",
            "    \n",
            "    encode_labels: (bool), if to encode labels as integer\n",
            "    \n",
            "    # Raises\n",
            "        ValueError:\n",
            "         - if train_test_split is not str ['random'] or float (<1 and >0)\"\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    TrainSet: dict,\n",
            "      - A dictionary with keys {'X_paths', 'Y', 'Y_encoded'}\n",
            "      - 'X_paths' is list of paths for audio files\n",
            "      - 'Y' is Nx1 np.array,\n",
            "      - 'Y_encoded' is Nx1 np.array same as 'Y', 0=true story 1=decptive story\n",
            "    \n",
            "    TestSet:\n",
            "      - A dictionary with keys {'X_paths', 'Y', 'Y_encoded'}\n",
            "      - same as TrainSet\n",
            "      - empty set, if `train_test_split=None`\n",
            "    \n",
            "    MAPs : A dictionary of maps, if encode_labels is true, else an empty dictionary\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 6 Experiments and results\n",
        "\n",
        "Carry out your experiments here. Analyse and explain your results. Unexplained results are worthless."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 7 Conclusions\n",
        "\n",
        "Your conclusions, suggestions for improvements, etc should go here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTcUkcuLhX91"
      },
      "source": [
        "# 8 References\n",
        "\n",
        "Acknowledge others here (books, papers, repositories, libraries, tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KVNSfPMhX92"
      },
      "source": [
        "# FINAL CHECK- CHECK EVERYTHING DONE. VAMOOOOOOOOOOOOS YOU GOT IT!!- final check with you know who- vamos\n",
        "- Text cells contain: description in  own words, **rigorously** and **concisely**\n",
        "    1.  your approach\n",
        "    2. each implemented step\n",
        "    3. the results that you obtain"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}