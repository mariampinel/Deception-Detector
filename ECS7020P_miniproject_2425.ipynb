{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariampinel/Deception-Detector/blob/main/ECS7020P_miniproject_2425.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91MsGMTna_P9"
      },
      "source": [
        "# ECS7020P mini-project submission\n",
        "\n",
        "\n",
        "## What is the problem?\n",
        "\n",
        "This year's mini-project considers the problem of predicting whether a narrated story is true or not. Specifically, you will build a machine learning model that takes as an input an audio recording of **30 seconds** of duration and predicts whether the story being narrated is **true or not**.\n",
        "\n",
        "\n",
        "## Which dataset will I use?\n",
        "\n",
        "A total of 100 samples consisting of a complete audio recording, a *Language* attribute and a *Story Type* attribute have been made available for you to build your machine learning model. The audio recordings can be downloaded from:\n",
        "\n",
        "https://github.com/MLEndDatasets/Deception/tree/main/MLEndDD_stories_small\n",
        "\n",
        "A CSV file recording the *Language* attribute and *Story Type* of each audio file can be downloaded from:\n",
        "\n",
        "https://github.com/MLEndDatasets/Deception/blob/main/MLEndDD_story_attributes_small.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## What will I submit?\n",
        "\n",
        "Your submission will consist of **one single Jupyter notebook** that should include:\n",
        "\n",
        "*   **Text cells**, describing in your own words, rigorously and concisely your approach, each implemented step and the results that you obtain,\n",
        "*   **Code cells**, implementing each step,\n",
        "*   **Output cells**, i.e. the output from each code cell,\n",
        "\n",
        "Your notebook **should have the structure** outlined below. Please make sure that you **run all the cells** and that the **output cells are saved** before submission.\n",
        "\n",
        "Please save your notebook as:\n",
        "\n",
        "* ECS7020P_miniproject_2425.ipynb\n",
        "\n",
        "\n",
        "## How will my submission be evaluated?\n",
        "\n",
        "This submission is worth 16 marks. We will value:\n",
        "\n",
        "*   Conciseness in your writing.\n",
        "*   Correctness in your methodology.\n",
        "*   Correctness in your analysis and conclusions.\n",
        "*   Completeness.\n",
        "*   Originality and efforts to try something new.\n",
        "\n",
        "**The final performance of your solutions will not influence your grade**. We will grade your understanding. If you have an good understanding, you will be using the right methodology, selecting the right approaches, assessing correctly the quality of your solutions, sometimes acknowledging that despite your attempts your solutions are not good enough, and critically reflecting on your work to suggest what you could have done differently.\n",
        "\n",
        "Note that **the problem that we are intending to solve is very difficult**. Do not despair if you do not get good results, **difficulty is precisely what makes it interesting** and **worth trying**.\n",
        "\n",
        "## Show the world what you can do\n",
        "\n",
        "Why don't you use **GitHub** to manage your project? GitHub can be used as a presentation card that showcases what you have done and gives evidence of your data science skills, knowledge and experience. **Potential employers are always looking for this kind of evidence**.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwJ1w8v8hX9g"
      },
      "source": [
        "-------------------------------------- PLEASE USE THE STRUCTURE BELOW THIS LINE --------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kozfd9uehX9j"
      },
      "source": [
        "# [Your title goes here]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**:  Maria Martinez\n",
        "**Student ID**:  240990523\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "\n",
        "Describe the machine learning problem that you want to solve and explain what's interesting about it.\n",
        "\n",
        "- This year's mini-project considers the problem of predicting whether a narrated story is true or not. Specifically, you will build a machine learning model that takes as an input an audio recording of **30 seconds** of duration and predicts whether the story being narrated is **true or not**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3n2Xt5IHJOn"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S50-e5_RHOH8"
      },
      "source": [
        "\n",
        "- Factors\n",
        "  - Lie is prepared, pre-thought\n",
        "  - Take into account silent periods: 0.1s or longer\n",
        "  - Identify: vocalizations, inspirations and expirations, tongue noises, laughs and giggles, and hiccoughs.\n",
        "  - Possible measures: rate of speech (the relationship between the number of\n",
        "syllables in the statement and its overall duration) and the rate of articula-\n",
        "tion (based on the length of the speech excluding filled and unfilled\n",
        "pauses)\n",
        "  - fundamental frequency (F0) was extracted using the spectral clipping method and zero crossing analysis. Also represents vocal fold excitation.\n",
        "  \n",
        "       Calculate mean, range and SD\n",
        "  - Verbal measures: 1) the number of arguments (1 =hair; 2 = age); (2) the\n",
        "total number of words; (3) the eloquency index (given by the ratio between\n",
        "number of words and number of arguments); and (4) the disfluency index\n",
        "(given by the sum of interrupted and repeated words).\n",
        "\n",
        "1.  31 male university students were asked to raise doubts in an expert in law about a picture. The subjects were required to describe the picture in three experimental conditions: telling the truth (T) and lying to a speaker when acquiescent (L1) and when suspicious (L2). The utterances were then subjected to a digitized acoustic analysis in order to measure nonverbal vocal variables\n",
        "\n",
        "**Evidence**\n",
        "  - Supported Predictors: the number of pauses {F = 4.67; p < .012) and the number of syllable. F0.\n",
        "  - Suggestion: Look at extreme values- Outliers might me tells for lies\n",
        "      - Calculate number of outliers of each sample\n",
        "      \n",
        "  - On the contrary, mean pause duration (considering filled and un-\n",
        "filled pauses separately), mean phrases and speech duration, and mean\n",
        "rate of articulation and language speed showed no significant overall ef-\n",
        "fect.\n",
        "- Calculate number of pauses. Why:\n",
        "    - The complexity of the cognitive task lies in the discrepancy between private knowledge and public statement: the liar (L) knows the truth (which he/she does not tell), but publicly tells a lie (which he/she does not believe, but has to make the H think that he/she does believe it). The cognitive conflict between the knowledge of truth and the encoded message denying (or concealing) it, as well as the need \"to disguise\" one's true beliefs, imply a saturation of the L's mental capacities making the\n",
        "task of deception all the more complex. This complexity, in fact, came to\n",
        "light in the research through the results of the experiment in the L1 condi-\n",
        "tion especially. These showed a rise in the number of shorter and more\n",
        "recurrent pauses which,\n",
        "2. There are 3 types of liars: : good liars, tense liars (more numerous in L1), and overcontrolled liars (more numerous in L2)\n",
        "\n",
        "- Find verbal leakage cues: Leakage cues can be found through psycholinguistic\n",
        "dictionaries such as the LIWC lexicon (Pennebaker\n",
        "et al., 1999), LDI (Bachenko et al., 2008; Enos,\n",
        "2009), and Harbingers (Niculae et al., 2015\n",
        "\n",
        "- Dealing with class unbalance: deal with\n",
        "the unbalanced labels in some datasets, we apply\n",
        "weighted binary cross-entropy loss and use the ratio\n",
        "of labels as the weight.\n",
        "\n",
        "**References**\n",
        "1. <https://link.springer.com/article/10.1023/A:1024916214403>\n",
        "2. <https://journals.sagepub.com/doi/full/10.1177/1088868314556539>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 3 Methodology\n",
        "\n",
        "Describe your methodology. Specifically, describe your training task and validation task, and how model performance is defined (i.e. accuracy, confusion matrix, etc). Any other tasks that might help you build your model should also be described here.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEj--JzcgXVD"
      },
      "source": [
        "**Approach**\n",
        "- Split dataset into training, validation and test sets\n",
        "  - Validation is used to select a suitable model to train. Used to select hyperparameters\n",
        "  - Validation technique: Stratified K-Fold Cross-Validation- allows to train hyperparameter of how many datasets to split trainSet into\n",
        "- Split samples into 30s samples\n",
        "- Feature extraction\n",
        "- Create function with audio files and csv (labels) file to create Nunmpy array with feature variables (features to extract from X_paths) as predictors and binary variable (y), indicates if story is true or deceptive\n",
        "  - Function outputs Array\n",
        "  - We don't have predictors organised with target var\n",
        "  - Apply function\n",
        "- Address class imbalance in dataset (seen doing shape of dataset)\n",
        "- Build model with predictive task\n",
        "- Apply model & get accuracy stats\n",
        "  - Improving accuracy: Normalization and regularization (Lab 4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 4 Implemented ML prediction pipelines\n",
        "\n",
        "Describe the ML prediction pipelines that you will explore. Clearly identify their input and output, stages and format of the intermediate data structures moving from one stage to the next. It's up to you to decide which stages to include in your pipeline. After providing an overview, describe in more detail each one of the stages that you have included in their corresponding subsections (i.e. 4.1 Transformation stage, 4.2 Model stage, 4.3 Ensemble stage)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "## 4.1 Transformation stage\n",
        "\n",
        "Describe any transformations, such as feature extraction. Identify input and output. Explain why you have chosen this transformation stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "## 4.2 Model stage\n",
        "\n",
        "Describe the ML model(s) that you will build. Explain why you have chosen them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dytPttlAhX9v"
      },
      "source": [
        "## 4.3 Ensemble stage\n",
        "\n",
        "Describe any ensemble approach you might have included. Explain why you have chosen them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 5 Dataset\n",
        "\n",
        "Describe the datasets that you will create to build and evaluate your models. Your datasets need to be based on our MLEnd Deception Dataset. After describing the datasets, build them here. You can explore and visualise the datasets here as well.\n",
        "\n",
        "If you are building separate training and validation datasets, do it here. Explain clearly how you are building such datasets, how you are ensuring that they serve their purpose (i.e. they are independent and consist of IID samples) and any limitations you might think of. It is always important to identify any limitations as early as possible. The scope and validity of your conclusions will depend on your ability to understand the limitations of your approach.\n",
        "\n",
        "If you are exploring different datasets, create different subsections for each dataset and give them a name (e.g. 5.1 Dataset A, 5.2 Dataset B, 5.3 Dataset 5.3) .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "LG_wAFhzmC1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0846056-5079-4c36-a6a7-c308ac444968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Import necessary packages\n",
        "!pip install pydub\n",
        "! pip install numpy librosa matplotlib\n",
        "! pip install tensorflow\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os, sys, re, pickle, glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "import librosa.display\n",
        "import math\n",
        "import random\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ueJgnnH_mQRt"
      },
      "outputs": [],
      "source": [
        "#Install library - make sure you have version 1.0.0.4\n",
        "%%capture\n",
        "!pip install mlend==1.0.0.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aQycsVll7BC-"
      },
      "outputs": [],
      "source": [
        "#Import library and functions\n",
        "%%capture\n",
        "import mlend\n",
        "from mlend import download_deception_small, deception_small_load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QjsQciHp7TKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad3434d-5efc-4ae2-b4d8-3791be933992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 100 stories (audio files) from https://github.com/MLEndDatasets/Deception\n",
            "\r  1%|\u001b[92m                                                  \u001b[0m|100\\1|00001.wav"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|\u001b[92m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[0m|100\\100|00100.wav\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#Download small data\n",
        "datadir = download_deception_small(save_to='MLEnd', subset={}, verbose=1, overwrite=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZQxEyUNK7T6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27dbb010-444a-4041-b9b0-81aa8ac856b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 100 found in MLEnd/deception/MLEndDD_stories_small/\n"
          ]
        }
      ],
      "source": [
        "#Read file paths\n",
        "TrainSet, TestSet, MAPs = deception_small_load(datadir_main=datadir, train_test_split=0.8, verbose=1, encode_labels=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract file paths (X) and labels (y) from TrainSet\n",
        "X_train_full = np.array(TrainSet['X_paths'])  # Full training file paths\n",
        "y_train_full = np.array(TrainSet['Y_encoded'])  # Corresponding labels\n",
        "\n",
        "X_test = np.array(TestSet['X_paths'])\n",
        "y_test = np.array(TestSet['Y_encoded'])"
      ],
      "metadata": {
        "id": "F9shIWhhDgnu"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full,\n",
        "    y_train_full,\n",
        "    test_size=0.25,  # 25% of TrainSet goes to Validation\n",
        "    stratify=y_train_full,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "XVgGyAnaAEx1"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Break down files into 30s files- 1) For training set, 2) for validation set 3) for test set\n",
        "\n",
        "def extract_segment(file_path, segment_length=30*1000):\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    total_length = len(audio)\n",
        "\n",
        "    # Make sure the total length is greater than or equal to the segment length\n",
        "    if total_length < segment_length:\n",
        "        raise ValueError(f\"Audio file {file_path} is shorter than the segment length.\")\n",
        "\n",
        "    # Randomly pick a starting point for the 30-second segment\n",
        "    start_time = random.randint(0, total_length - segment_length)\n",
        "    end_time = start_time + segment_length\n",
        "\n",
        "    segment = audio[start_time:end_time]\n",
        "\n",
        "    # Save the extracted segment\n",
        "    output_file = f\"{file_path[:-4]}_random_segment.wav\"\n",
        "    segment.export(output_file, format=\"wav\")\n",
        "    # num_segments = math.ceil(total_length  / segment_length )\n",
        "    # segment_paths = []\n",
        "\n",
        "    # for i in range(num_segments):\n",
        "    #     start_time = max(0, i * segment_length )\n",
        "    #     end_time = min(total_length, start_time + segment_length)\n",
        "    #     segment = audio[start_time:end_time]\n",
        "\n",
        "        # output_file = f\"{file_path[:-4]}_part{i+1}.wav\"\n",
        "        # segment.export(output_file, format=\"wav\")\n",
        "        # segment_paths.append(output_file)\n",
        "    # Close the AudioSegment object after exporting\n",
        "    audio = None  # Explicitly delete to free up resources\n",
        "\n",
        "\n",
        "    return output_file #segment_paths\n",
        "\n"
      ],
      "metadata": {
        "id": "X0i31jxjk-p9"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F-rgmkfWQOYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Generate 30-second segments for each dataset\n",
        "def generate_segments_and_labels(file_paths, labels, num_segments=1):\n",
        "    segment_paths = []\n",
        "    segment_labels = []\n",
        "\n",
        "    for file_path, label in zip(file_paths, labels):\n",
        "      for _ in range(num_segments):\n",
        "          # Extract a random 30-second segment\n",
        "          segment = extract_segment(file_path, segment_length=30*1000)\n",
        "          # Append the segment and its corresponding label\n",
        "          segment_paths.append(segment)\n",
        "          segment_labels.append(label)\n",
        "        # # Split audio into segments\n",
        "        # segments = split_audio(file_path, segment_length=30*1000)\n",
        "        # # Append segments and their corresponding labels\n",
        "        # segment_paths.extend(segments)\n",
        "        # segment_labels.extend([label] * len(segments))\n",
        "\n",
        "    return segment_paths, segment_labels"
      ],
      "metadata": {
        "id": "bzVOAZ6yA_b-"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 30-second segments for each dataset - PUT THIS PART AT THE END. JUST BEFRO RUNNING MODEL\n",
        "X_train_segments, y_train_segments = generate_segments_and_labels(X_train, y_train)\n",
        "X_valid_segments, y_valid_segments = generate_segments_and_labels(X_valid, y_valid)\n",
        "X_test_segments, y_test_segments = generate_segments_and_labels(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "2cHKeRgsAK6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d3ec66-6b45-4eb9-9782-59f82062d491"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00034.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00034_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00075.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00075_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00016.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00016_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00007.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00007_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00009.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00009_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00089.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00089_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00004.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00004_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00081.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00081_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00076.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00076_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00047.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00047_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00051.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00051_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00012.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00012_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00013.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00013_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00037.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00037_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00008.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00008_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00100.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00100_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00070.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00070_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00050.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00050_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00092.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00092_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00024.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00024_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00065.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00065_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00045.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00045_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00071.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00071_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00032.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00032_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00031.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00031_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00043.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00043_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00082.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00082_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00088.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00088_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00086.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00086_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00001.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00001_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00014.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00014_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00023.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00023_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00084.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00084_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00052.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00052_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00038.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00038_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00067.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00067_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00053.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00053_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00093.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00093_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00074.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00074_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00017.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00017_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00039.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00039_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00085.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00085_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00046.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00046_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00087.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00087_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00019.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00019_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00005.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00005_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00010.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00010_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00080.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00080_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00066.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00066_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00090.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00090_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00002.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00002_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00072.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00072_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00026.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00026_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00029.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00029_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00077.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00077_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00097.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00097_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00030.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00030_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00078.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00078_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00055.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00055_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00094.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00094_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00083.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00083_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00044.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00044_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00064.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00064_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00056.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00056_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00058.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00058_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00035.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00035_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00015.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00015_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00068.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00068_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00049.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00049_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00006.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00006_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00011.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00011_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00096.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00096_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00099.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00099_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00079.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00079_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00098.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00098_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00020.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00020_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00033.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00033_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00054.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00054_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00073.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00073_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00028.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00028_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00003.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00003_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00018.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00018_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00021.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00021_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00022.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00022_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00025.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00025_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00027.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00027_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00036.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00036_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00040.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00040_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00041.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00041_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00042.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00042_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00048.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00048_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00057.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00057_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00059.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00059_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00060.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00060_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00061.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00061_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00062.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00062_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00063.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00063_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00069.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00069_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00091.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00091_random_segment.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:4: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00095.wav'>\n",
            "<ipython-input-251-e3af2ded092e>:19: ResourceWarning: unclosed file <_io.BufferedRandom name='MLEnd/deception/MLEndDD_stories_small/00095_random_segment.wav'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hm7zZ0M5T5I"
      },
      "source": [
        "- Training set is 80% of original dataset\n",
        "- Training set TrainSet is then further split into training and validation datastet\n",
        "- New training set is now 75% of TrainSet and validation set is 25% of TrainSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7TNbpWwy68O"
      },
      "source": [
        "- Code splits audio files into 30s files, accounting for segments with few seconds, removing if not above a minimum threshold.\n",
        "- We overlap segments because model may benefit from repeated context, for speech recognition. Why? It benefits because the tasks requires continuity over segments. Hence, we avoid boundary effects.\n",
        "\n",
        "Took out ovelap because the model has to output a classification for one 30second audio. so if we include overlap, it will be overfitting, and reducting the accuracy,because the model only has one 30s input, not 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfJ_WAS87aoq"
      },
      "outputs": [],
      "source": [
        "#To read the documentation on the given functions run:\n",
        "# help(download_deception_small)\n",
        "# help(deception_small_load)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 6 Experiments and results\n",
        "\n",
        "Carry out your experiments here. Analyse and explain your results. Unexplained results are worthless."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features:\n",
        "- F0: Vocal fold excitation\n",
        "- Explain i tried using this function but that it would caluclate a sample rate that would create errors in later processing. It nsures feature consistency, and avoids errors related to varying Nyquist frequencies or feature dimensionality.\n"
      ],
      "metadata": {
        "id": "uizMLSj7v1fJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3Qq0UbLIUqo"
      },
      "outputs": [],
      "source": [
        "def getPitch(x,fs,winLen=0.02):\n",
        "  #winLen = 0.02\n",
        "  p = winLen*fs\n",
        "  frame_length = int(2**int(p-1).bit_length())\n",
        "  hop_length = frame_length//2\n",
        "  f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs,\n",
        "                                                 frame_length=frame_length,hop_length=hop_length)\n",
        "  return f0,voiced_flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdqh5osmCkAb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_features(file_path, scale_audio=False):\n",
        "    # Load the audio file (30 seconds duration)\n",
        "\n",
        "    x, fs = librosa.load(file_path,sr=None, duration=30.0)\n",
        "    if scale_audio: x = x/np.max(np.abs(x)) # Normalize audio\n",
        "    f0, voiced_flag = getPitch(x,fs,winLen=0.02) #extract pitch and voice features\n",
        "\n",
        "    #Power and pitch\n",
        "    power = np.sum(x**2)/len(x)\n",
        "    pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "    pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "    voiced_fr = np.mean(voiced_flag)\n",
        "\n",
        "    # Extract MFCCs (Mel-frequency cepstral coefficients)\n",
        "    mfccs = librosa.feature.mfcc(y=x, sr=fs, n_mfcc=40)\n",
        "    mfccs_first_5 = mfccs[:5, :]  # Slicing to keep the first 5 MFCC coefficients\n",
        "    mfccs_mean = np.mean(mfccs_first_5, axis=1)  # Take the mean for each MFCC\n",
        "    mfccs_std= np.std(mfccs_first_5, axis=1)\n",
        "\n",
        "    # Extract Chroma feature\n",
        "    chroma = librosa.feature.chroma_stft(y=x, sr=fs)\n",
        "    chroma_mean = np.mean(chroma, axis=1)  # Mean for each chroma feature\n",
        "\n",
        "    # # Extract Spectral Contrast\n",
        "    # spectral_contrast = librosa.feature.spectral_contrast(y=x, sr=fs)\n",
        "    # spectral_contrast_mean = np.mean(spectral_contrast, axis=1)  # Mean for each spectral contrast feature\n",
        "\n",
        "    # Extract Zero-Crossing Rate\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(x)\n",
        "    zero_crossing_rate_mean = np.mean(zero_crossing_rate, axis=1)  # Mean for zero-crossing rate\n",
        "\n",
        "    # Extract Spectral Bandwidth\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=x, sr=fs)\n",
        "    spectral_bandwidth_mean = np.mean(spectral_bandwidth, axis=1)  # Mean for spectral bandwidth\n",
        "\n",
        "    # Combine all the features into one array- DELETED: spectral_contrast_mean\n",
        "    features = np.hstack([mfccs_mean, mfccs_std, chroma_mean, zero_crossing_rate_mean, spectral_bandwidth_mean, power,pitch_mean,pitch_std,voiced_fr])\n",
        "\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My extraction function\n",
        "- Use librosa's Harmonic/Percussive component separation (HPSS)\n",
        "\n",
        "- HNM: The Harmonics Plus Noise Model (HNM) is a more general model that separates an audio signal into harmonic and noise components, where the noise part includes all non-harmonic elements. This noise component is often more complex than the \"percussive\" component in HPSS and can include things like speech background noise, environmental sounds, or other forms of aperiodic noise.\n",
        "- Harmonic Component: As in HPSS, the harmonic component represents the periodic (tonal) parts of the signal, which are often associated with the fundamental frequency or pitch.\n",
        "harmonic_mfccs_std deleted. Not using anymore: too computationally demanding.\n",
        "- Noise Component: This represents everything else that is not harmonic, including aperiodic sounds such as speech noise, wind, or other ambient environmental sounds.\n",
        "- Speech Analysis: HNM is often used in speech and voice processing, where noise could be environmental sound or unvoiced speech components, and harmonics could represent voiced speech sounds.\n",
        "More Detailed Noise Modeling: It’s typically more effective in scenarios where the noise is not simply percussive (e.g., environmental noise, background sounds in speech).\n",
        "\n",
        "\n",
        "\n",
        "- MFCC:  MFCC: MFCC, inspired by the human\n",
        "auditory system, is a popular method for\n",
        "feature extraction in speech recognition. It\n",
        "involves pre-emphasis, framing,\n",
        "windowing, Fast Fourier Transform (FFT),\n",
        "Mel filter bank, and computing Discrete Cosine Transform (DCT). MFCC is\n",
        "favored for its simplicity, effectiveness,\n",
        "and robustness across various conditions\n",
        "<https://www.researchgate.net/profile/I-Venkata-Srihith/publication/380465368_The_Voice_of_Feeling_Exploring_Emotions_via_Machine_Learning/links/663dc10335243041538557c1/The-Voice-of-Feeling-Exploring-Emotions-via-Machine-Learning.pdf>\n",
        " -  Tried to extract python3 extract_pauses_1.py path_to_audio_file n y as a feature but ran into extraction problems. i had to call a subprocess function to use external"
      ],
      "metadata": {
        "id": "IE9Mb3Du-RZv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_esZjkTLas3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oEnu-AMYasz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y sox\n",
        "!apt-get install -y ffmpeg\n",
        "!apt-get update --fix-missing\n",
        "!apt-get install -y curl\n",
        "!pip install ffmpeg-python\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNar_mAMZJeP",
        "outputId": "b07fbcc9-60f7-4b9b-d554-fd5e26dc1677"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.81)] [Connecting to cloud.r-p\r                                                                                                    \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                                                    \rGet:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (18.239.18.118)] [Connecting to r2u.stat.\r                                                                                                    \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,514 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,446 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [53.3 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,190 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,225 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,624 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,525 kB]\n",
            "Fetched 24.2 MB in 5s (5,352 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox3 libwavpack1\n",
            "Suggested packages:\n",
            "  libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox3 libwavpack1 sox\n",
            "0 upgraded, 7 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 617 kB of archives.\n",
            "After this operation, 1,764 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 sox amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [104 kB]\n",
            "Fetched 617 kB in 0s (5,145 kB/s)\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../2-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../3-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../4-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../5-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../6-sox_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.81.0-1ubuntu1.19).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/ffmpeg_python-0.2.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install python-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOdoEkqobpCa",
        "outputId": "5a909e1d-b3c8-41d7-acfb-15dab78a2dc0"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-utils in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: typing_extensions>3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from python-utils) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Silence detection function (no changes here, already efficient)\n",
        "import librosa\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "import itertools\n",
        "from concurrent.futures import ProcessPoolExecutor  # For parallel processing\n",
        "\n",
        "def db_to_float(db):\n",
        "    \"\"\"Converts a decibel value to a linear amplitude value.\"\"\"\n",
        "    return 10**(db/20)\n",
        "\n",
        "def detect_silence(audio_segment, min_silence_len=500, silence_thresh=-16, seek_step=5):\n",
        "    seg_len = len(audio_segment)\n",
        "    if seg_len < min_silence_len:\n",
        "        return []\n",
        "\n",
        "    silence_thresh = db_to_float(silence_thresh) * audio_segment.max_possible_amplitude\n",
        "    silence_starts = []\n",
        "    last_slice_start = seg_len - min_silence_len\n",
        "    slice_starts = range(0, last_slice_start + 1, seek_step)\n",
        "\n",
        "    if last_slice_start % seek_step:\n",
        "        slice_starts = itertools.chain(slice_starts, [last_slice_start])\n",
        "\n",
        "    for i in slice_starts:\n",
        "        audio_slice = audio_segment[i:i + min_silence_len]\n",
        "        if audio_slice.rms <= silence_thresh:\n",
        "            silence_starts.append(i)\n",
        "\n",
        "    if not silence_starts:\n",
        "        return []\n",
        "\n",
        "    silent_ranges = []\n",
        "    prev_i = silence_starts.pop(0)\n",
        "    current_range_start = prev_i\n",
        "\n",
        "    for silence_start_i in silence_starts:\n",
        "        continuous = (silence_start_i == prev_i + seek_step)\n",
        "        silence_has_gap = silence_start_i > (prev_i + min_silence_len)\n",
        "\n",
        "        if not continuous and silence_has_gap:\n",
        "            silent_ranges.append([current_range_start, prev_i + min_silence_len])\n",
        "            current_range_start = silence_start_i\n",
        "        prev_i = silence_start_i\n",
        "\n",
        "    silent_ranges.append([current_range_start, prev_i + min_silence_len])\n",
        "    return silent_ranges\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q3eNSsFVXVCu"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maria's extraction function\n",
        "\n",
        "def extract_features(file_path, scale_audio=False, sr=22050):\n",
        "    # Load the audio file (30 seconds duration)\n",
        "    x, fs = librosa.load(file_path, sr=sr, duration=30.0)\n",
        "\n",
        "    if scale_audio:\n",
        "        x = x / np.max(np.abs(x))  # Normalize audio\n",
        "\n",
        "    # # Extract pitch and voiced features (harmonic part)\n",
        "    # f0, voiced_flag = getPitch(x, fs, winLen=0.02)\n",
        "\n",
        "    # # Power and pitch statistics\n",
        "    # power = np.sum(x**2) / len(x)\n",
        "    # pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0)) < 1 else 0\n",
        "    # pitch_std = np.nanstd(f0) if np.mean(np.isnan(f0)) < 1 else 0\n",
        "    # voiced_fr = np.mean(voiced_flag)\n",
        "\n",
        "    # Extract MFCCs from the full signal\n",
        "    mfccs = librosa.feature.mfcc(y=x, sr=fs, n_mfcc=40)\n",
        "    mfccs_first_5 = mfccs[:5, :]  # Slicing to keep the first 5 MFCC coefficients\n",
        "    mfccs_mean = np.mean(mfccs_first_5, axis=1)  # Mean for each MFCC\n",
        "    mfccs_std = np.std(mfccs_first_5, axis=1)\n",
        "\n",
        "    # # Extract Chroma feature\n",
        "    # chroma = librosa.feature.chroma_stft(y=x, sr=fs)\n",
        "    # chroma_mean = np.mean(chroma, axis=1)  # Mean for each chroma feature\n",
        "\n",
        "    # # Extract Zero-Crossing Rate\n",
        "    # zero_crossing_rate = librosa.feature.zero_crossing_rate(x)\n",
        "    # zero_crossing_rate_mean = np.mean(zero_crossing_rate, axis=1)  # Mean for zero-crossing rate\n",
        "\n",
        "    # # Extract Spectral Bandwidth\n",
        "    # spectral_bandwidth = librosa.feature.spectral_bandwidth(y=x, sr=fs)\n",
        "    # spectral_bandwidth_mean = np.mean(spectral_bandwidth, axis=1)  # Mean for spectral bandwidth\n",
        "\n",
        "    # Harmonics Plus Noise Model (HNM) - Using HPSS as an approximation\n",
        "    # harmonic, noise = librosa.effects.hpss(x)\n",
        "\n",
        "    # noise_mfccs = librosa.feature.mfcc(y=noise, sr=fs, n_mfcc=5)\n",
        "    # noise_mfccs_mean = np.mean(noise_mfccs, axis=1)\n",
        "    # noise_mfccs_std = np.std(noise_mfccs, axis=1)\n",
        "\n",
        "    # # Extract the harmonic power\n",
        "    # harmonic_power = np.sum(harmonic**2) / len(harmonic)\n",
        "\n",
        "    # # Extract the noise power\n",
        "    # noise_power = np.sum(noise**2) / len(noise)\n",
        "\n",
        "    # # Calculate Harmonics-to-Noise Ratio (HNR)\n",
        "    # if noise_power > 0:\n",
        "    #     hnr = 10 * np.log10(harmonic_power / noise_power)\n",
        "    # else:\n",
        "    #     hnr = 0  # Avoid division by zero, set to 0 if noise power is zero\n",
        "\n",
        "    # Convert to AudioSegment to use with the silence detection\n",
        "    audio_segment = AudioSegment.from_wav(file_path)\n",
        "\n",
        "    # Detect silences in the audio\n",
        "    silent_ranges = detect_silence(audio_segment)\n",
        "\n",
        "    # # Calculate silence percentage or number of silent ranges\n",
        "    # total_silence_duration = sum([end - start for start, end in silent_ranges])  # Total silence in ms\n",
        "    # silence_percentage = total_silence_duration / len(audio_segment) * 100  # Percentage of silence in audio\n",
        "  # # Calculate silence percentage (e.g., proportion of the time where the RMS energy is below a threshold)\n",
        "  #   silence = librosa.effects.split(x, top_db=30)  # Use energy-based voice activity detection\n",
        "  #   silence_percentage = 100 * (len(x) - sum([end - start for start, end in silence])) / len(x)\n",
        "    # Use librosa's split function to get non-silent sections\n",
        "    non_silent_sections = librosa.effects.split(x, top_db=30)  # Energy-based silence detection\n",
        "\n",
        "    # Calculate silence features\n",
        "    pause_durations = []\n",
        "    for start, end in non_silent_sections:\n",
        "        pause_durations.append((end - start))  # Collect the lengths of silent sections\n",
        "\n",
        "    num_pauses = len(pause_durations)  # Number of pauses\n",
        "    avg_pause_duration = np.mean(pause_durations) if num_pauses > 0 else 0  # Average pause duration\n",
        "    pause_duration_variability = np.std(pause_durations) if num_pauses > 0 else 0  # Pause duration variability (std)\n",
        "\n",
        "    # Combine all the features into one array\n",
        "    features = np.hstack([mfccs_mean, mfccs_std, num_pauses, avg_pause_duration, pause_duration_variability])\n",
        "\n",
        "# harmonic_mfccs_mean, harmonic_mfccs_std, chroma_mean,  zero_crossing_rate_mean, spectral_bandwidth_mean, power, pitch_mean, pitch_std, voiced_fr,  harmonic_power, noise_power, hnr  , noise_mfccs_mean, noise_mfccs_std,\n",
        "\n",
        "    return features\n",
        "\n"
      ],
      "metadata": {
        "id": "83ioviCG9hVq"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maria's extraction function 2\n",
        "def extract_features(file_path, scale_audio=False, sr=22050):\n",
        "    # Load the audio file (30 seconds duration)\n",
        "    x, fs = librosa.load(file_path, sr=sr, duration=30.0)\n",
        "\n",
        "    if scale_audio:\n",
        "        x = x / np.max(np.abs(x))  # Normalize audio\n",
        "\n",
        "    # Extract pitch and voiced features (harmonic part)\n",
        "    f0, voiced_flag, voiced_probs = librosa.pyin(x, fmin=80, fmax=450, sr=fs)\n",
        "\n",
        "    # Power and pitch statistics\n",
        "    pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0)) < 1 else 0\n",
        "    pitch_std = np.nanstd(f0) if np.mean(np.isnan(f0)) < 1 else 0\n",
        "\n",
        "    # Silence detection (pause features)\n",
        "    silent_ranges = librosa.effects.split(x, top_db=30)\n",
        "    num_pauses = len(silent_ranges)\n",
        "    avg_pause_duration = np.mean([end - start for start, end in silent_ranges]) / fs\n",
        "\n",
        "    # Extract MFCCs (Mel-frequency cepstral coefficients)\n",
        "    mfccs = librosa.feature.mfcc(y=x, sr=fs, n_mfcc=5)\n",
        "    mfccs_mean = np.mean(mfccs, axis=1)  # Mean of the first 5 MFCC coefficients\n",
        "\n",
        "    # Combine the reduced set of features\n",
        "    features = np.hstack([mfccs_mean, pitch_mean, pitch_std, num_pauses, avg_pause_duration])\n",
        "\n",
        "    return features\n",
        "\n"
      ],
      "metadata": {
        "id": "ibB3lUcny21e"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and THIS ONE:\n",
        "def segment_feature_extraction(segment_paths):\n",
        "    features = []\n",
        "    for segment_path in segment_paths:\n",
        "        features.append(extract_features(segment_path))\n",
        "    features = np.array(features)\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "k7h7LgYbBbIu"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LNqExgnK3f4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 1: CNN"
      ],
      "metadata": {
        "id": "4SeyM7uP3gb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a 1D Convolutional Neural Network- Why? Because audio features have a time dimension\n",
        "# From a practical point of view, it seems like a 1D CNN would reduce the computational costs and amount of data required to train compared to a 2D CNN.\n",
        "\n",
        "num_features= 3\n",
        "#Build sequential CNN\n",
        "CNN_model = Sequential()\n",
        "\n",
        "#Build first layer\n",
        "CNN_model.add(Conv1D(16, 5,padding='same', input_shape=(num_features, 1), activation='relu'))\n",
        "\n",
        "CNN_model.add(Conv1D(32, 5,padding='same',activation='relu'))#Build second layer\n",
        "CNN_model.add(Conv1D(64, 5,padding='same',activation='relu'))#Build third layer\n",
        "CNN_model.add(Conv1D(128, 5,padding='same',activation='relu'))#Build forth layer\n",
        "\n",
        "CNN_model.add(Dropout(0.1))#Add dropout\n",
        "CNN_model.add(Flatten())#Flatten\n",
        "CNN_model.add(Dense(128, activation ='relu'))\n",
        "CNN_model.add(Dense(64, activation ='relu'))\n",
        "CNN_model.add(Dense(8, activation='softmax'))"
      ],
      "metadata": {
        "id": "F0powuQJsJnZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features= 3\n",
        "#Build sequential CNN\n",
        "CNN_model = Sequential()\n",
        "\n",
        "# Add Conv1D layers (since you're working with 1D features)\n",
        "CNN_model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=( num_features, 1)))  # 10 features per sample, 1 channel\n",
        "CNN_model.add(MaxPooling1D(pool_size=2))\n",
        "CNN_model.add(Flatten())  # Flatten the output for the dense layer\n",
        "CNN_model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# CNN_model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification (2 classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "4WB0ts0E_oM4"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with the desired loss function, optimizer, and metric to optimize\n",
        "CNN_model.compile(loss = 'binary_crossentropy',\n",
        "                  optimizer = 'Adam',\n",
        "                  metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "CGOzlRBMu9d4"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract features for each dataset - Put at the end\n",
        "X_train_features = segment_feature_extraction(X_train_segments)\n",
        "X_valid_features = segment_feature_extraction(X_valid_segments)\n",
        "X_test_features = segment_feature_extraction(X_test_segments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4rM-sgSoaeX",
        "outputId": "158b9959-287d-4a3c-aefc-f627cdde3709"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydub/audio_segment.py:808: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00091_part8.wav'>\n",
            "/usr/local/lib/python3.10/dist-packages/pydub/audio_segment.py:808: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00095_part1.wav'>\n",
            "/usr/local/lib/python3.10/dist-packages/pydub/audio_segment.py:808: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00095_part2.wav'>\n",
            "/usr/local/lib/python3.10/dist-packages/pydub/audio_segment.py:808: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00095_part3.wav'>\n",
            "/usr/local/lib/python3.10/dist-packages/pydub/audio_segment.py:808: ResourceWarning: unclosed file <_io.BufferedReader name='MLEnd/deception/MLEndDD_stories_small/00095_part4.wav'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Reshape for Conv1D (ensure 3D array: [n_samples, sequence_length, n_channels])\n",
        "# X_train_features = X_train_features.reshape(X_train_features.shape[0], X_train_features.shape[1], 1)\n",
        "# X_valid_features = X_valid_features.reshape(X_valid_features.shape[0], X_valid_features.shape[1], 1)\n",
        "# X_test_features = X_test_features.reshape(X_test_features.shape[0], X_test_features.shape[1], 1)\n",
        "\n",
        "# Reshape features for Conv1D (ensure 3D array: [n_samples, sequence_length, n_channels])\n",
        "X_train_features = X_train_features.reshape(X_train_features.shape[0], 3, 1)\n",
        "X_valid_features = X_valid_features.reshape(X_valid_features.shape[0], 3, 1)\n",
        "X_test_features = X_test_features.reshape(X_test_features.shape[0], 3, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "aCv28EAPB00v",
        "outputId": "8e0d9fa8-6ba5-405b-d005-10e9437eb59f"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 3432 into shape (312,3,1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-194-c100b5441411>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Reshape features for Conv1D (ensure 3D array: [n_samples, sequence_length, n_channels])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_valid_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_valid_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX_test_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3432 into shape (312,3,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shapes after reshaping for Conv1D:\")\n",
        "print(f\"Train Features Shape: {X_train_features.shape}\")\n",
        "print(f\"Validation Features Shape: {X_valid_features.shape}\")\n",
        "print(f\"Test Features Shape: {X_test_features.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptFrU4QPB7Vz",
        "outputId": "cb58151b-860c-42da-8139-e46fc80f3e52"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes after reshaping for Conv1D:\n",
            "Train Features Shape: (312, 11, 1)\n",
            "Validation Features Shape: (101, 11, 1)\n",
            "Test Features Shape: (107, 11, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shapes of Labels:\")\n",
        "print(len(y_train_segments), len(X_train_features))\n",
        "print(f\"y_valid: {len(y_valid_segments), len(X_valid_features)}\")\n",
        "print(f\"y_test: {len(y_test_segments),  len(X_test_features)}\")\n",
        "\n",
        "assert len(X_train_features) == len(y_train_segments), \"Mismatch in X_train and y_train sizes!\"\n",
        "assert len(X_valid_features) == len(y_valid_segments), \"Mismatch in X_valid and y_valid sizes!\"\n",
        "assert len(X_test_features) == len(y_valid_segments), \"Mismatch in X_test and y_test sizes!\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "jfnSLGZBCNRG",
        "outputId": "cdd74e17-59d2-4406-ae9f-933e1e696cf9"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of Labels:\n",
            "312 312\n",
            "y_valid: (101, 101)\n",
            "y_test: (107, 107)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Mismatch in X_test and y_test sizes!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-1c3665eefe2b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Mismatch in X_train and y_train sizes!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Mismatch in X_valid and y_valid sizes!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Mismatch in X_test and y_test sizes!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: Mismatch in X_test and y_test sizes!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_segments = to_categorical(y_train_segments, num_classes=2)\n",
        "y_valid_segments = to_categorical(y_valid_segments, num_classes=2)\n",
        "y_test_segments = to_categorical(y_test_segments, num_classes=2)\n"
      ],
      "metadata": {
        "id": "rdrNOT89_9_T"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape features to 2D for scaling\n",
        "X_train_flat = X_train_features.reshape(-1, X_train_features.shape[2])  # Flatten sequence dimension\n",
        "X_valid_flat = X_valid_features.reshape(-1, X_valid_features.shape[2])\n",
        "X_test_flat = X_test_features.reshape(-1, X_test_features.shape[2])\n",
        "# Scale data- to prevent model to fit volume level of recordings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_valid_scaled_flat = scaler.transform(X_valid_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape back to 3D for Conv1D\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train_features.shape)\n",
        "X_valid_scaled = X_valid_scaled_flat.reshape(X_valid_features.shape)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test_features.shape)"
      ],
      "metadata": {
        "id": "aVjuiXgZrEIY"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Remove unnecessary dimensions from target labels\n",
        "# y_train_segments = y_train_segments.reshape(-1, y_train_segments.shape[2])\n",
        "# y_valid_segments = y_valid_segments.reshape(-1, y_valid_segments.shape[2])\n",
        "# y_test_segments = y_test_segments.reshape(-1, y_test_segments.shape[2])\n",
        "\n",
        "# Verify the shapes\n",
        "print(\"Corrected Shapes of Target Labels:\")\n",
        "print(f\"y_train_segments: {y_train_segments.shape}\")\n",
        "print(f\"y_valid_segments: {y_valid_segments.shape}\")\n",
        "print(f\"y_test_segments: {y_test_segments.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y91rTe9KPyUv",
        "outputId": "73028791-7c81-4747-9206-3f58310ab6a0"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Shapes of Target Labels:\n",
            "y_train_segments: (1248, 2)\n",
            "y_valid_segments: (404, 2)\n",
            "y_test_segments: (428, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit CNN model\n",
        "#Model fit\n",
        "cnn_results = CNN_model.fit(X_train_scaled, y_train_segments,\n",
        "                             batch_size=64,\n",
        "                             epochs=25,\n",
        "                             verbose=1,\n",
        "                             validation_data=(X_valid_scaled, y_valid_segments))\n"
      ],
      "metadata": {
        "id": "Xi6Q4M1w2CUg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c8f945fa-7fcc-47f0-9ab4-c4408ec7fe55"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 312\n'y' sizes: 1248\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-189-69e143d9442a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit CNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Model fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m cnn_results = CNN_model.fit(X_train_scaled, y_train_segments,\n\u001b[0m\u001b[1;32m      4\u001b[0m                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/data_adapter_utils.py\u001b[0m in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    112\u001b[0m             )\n\u001b[1;32m    113\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"'{label}' sizes: {sizes}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 312\n'y' sizes: 1248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Evaluate on the test set\n",
        "test_loss, test_accuracy = CNN_model.evaluate(X_test_scaled, y_test_segments, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "id": "vhrug91c2Efs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf5f6bf-77ca-4c74-8983-b64bf59b61b5"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3922 - loss: 0.7070 \n",
            "Test Loss: 0.7058152556419373, Test Accuracy: 0.37383177876472473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred_proba = CNN_model.predict(X_test_scaled)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# Get the true class labels\n",
        "y_true = np.argmax(y_test_segments, axis=1)  # Convert one-hot encoding to class labels\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Display the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title(\"Confusion Matrix for CNN Model\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "XDgHNLI3S-cn",
        "outputId": "60f29988-a60d-41da-f292-066c10a21bc2"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define text cleaning and processing text pipeline"
      ],
      "metadata": {
        "id": "_8kUZ4DZCcZ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8r2LKACb-8V"
      },
      "outputs": [],
      "source": [
        "# Plotting audio sample\n",
        "n=0\n",
        "fs = 30 # Sampling frequency\n",
        "x, fs = librosa.load(TrainSet['X_paths'][n],sr=fs)\n",
        "t = np.arange(len(x))/fs\n",
        "plt.plot(t,x)\n",
        "plt.xlabel('time (sec)')\n",
        "plt.ylabel('amplitude')\n",
        "plt.show()\n",
        "display(ipd.Audio(TrainSet['X_paths'][n]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 2: SVM\n"
      ],
      "metadata": {
        "id": "caWUhsJKL2n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract features for each dataset - Put at the end\n",
        "X_train_features = segment_feature_extraction(X_train_segments)\n",
        "X_valid_features = segment_feature_extraction(X_valid_segments)\n",
        "X_test_features = segment_feature_extraction(X_test_segments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "8UWpnEiulkyI",
        "outputId": "35f0dd1e-11a4-464c-d4cf-9aef11738e93"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "CPUDispatcher(<function _viterbi at 0x793ce93b12d0>) returned a result with an exception set",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/serialize.py\u001b[0m in \u001b[0;36m_numba_unpickle\u001b[0;34m(address, bytedata, hashed)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_numba_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytedata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \"\"\"Used by `numba_unpickle` from _helperlib.c\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;31mSystemError\u001b[0m: _PyEval_EvalFrameDefault returned a result with an exception set",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-260-583cf6d42c61>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract features for each dataset - Put at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_feature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_valid_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_feature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_test_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_feature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-259-f9352128a55a>\u001b[0m in \u001b[0;36msegment_feature_extraction\u001b[0;34m(segment_paths)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msegment_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msegment_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-258-09050a4c7388>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(file_path, scale_audio, sr)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Extract pitch and voiced features (harmonic part)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoiced_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoiced_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m450\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Power and pitch statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/pitch.py\u001b[0m in \u001b[0;36mpyin\u001b[0;34m(y, fmin, fmax, sr, frame_length, win_length, hop_length, n_thresholds, beta_parameters, boltzmann_parameter, resolution, max_transition_rate, switch_prob, no_trough_prob, fill_na, center, pad_mode)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0mp_init\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_pitch_bins\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_pitch_bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m     \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;31m# Find f0 corresponding to each decoded pitch bin.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/sequence.py\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(prob, transition, p_init, return_logp)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         )\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__viterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;31m# Flatten out the trailing dimension introduced by vectorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2370\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_as_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_call_as_normal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2363\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2444\u001b[0m         \u001b[0;34m\"\"\"Vectorized call to `func` over positional `args`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call_with_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call_with_signature\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbroadcast_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m             \u001b[0mn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/sequence.py\u001b[0m in \u001b[0;36m_helper\u001b[0;34m(lp)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;31m# Transpose input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         \u001b[0m_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_viterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_p_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0;31m# Transpose outputs for return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: CPUDispatcher(<function _viterbi at 0x793ce93b12d0>) returned a result with an exception set"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v3U8JxD2umuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape for Conv1D (ensure 3D array: [n_samples, sequence_length, n_channels])\n",
        "#  sequence_length = 5 (number of features) and n_channels = 1 (single feature channel)\n",
        "X_train_features = X_train_features.reshape(X_train_features.shape[0],15, 1)\n",
        "X_valid_features = X_valid_features.reshape(X_valid_features.shape[0], 15, 1)\n",
        "X_test_features = X_test_features.reshape(X_test_features.shape[0], 15, 1)\n",
        "\n",
        "# Print reshaped data for Conv1D (3D data)\n",
        "print(f\"Reshaped X_train_features for Conv1D: {X_train_features.shape}\")\n",
        "print(f\"Reshaped X_valid_features for Conv1D: {X_valid_features.shape}\")\n",
        "print(f\"Reshaped X_test_features for Conv1D: {X_test_features.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJbxICCHmsdD",
        "outputId": "c251b304-9dc1-4392-9d78-94f630ac8680"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped X_train_features for Conv1D: (312, 15)\n",
            "Reshaped X_valid_features for Conv1D: (101, 15)\n",
            "Reshaped X_test_features for Conv1D: (107, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the data (from 3D to 2D) for SVM, RandomForest, XGBoost\n",
        "X_train_flat = X_train_features.reshape(X_train_features.shape[0], -1)\n",
        "X_valid_flat = X_valid_features.reshape(X_valid_features.shape[0], -1)\n",
        "X_test_flat = X_test_features.reshape(X_test_features.shape[0], -1)\n",
        "\n",
        "print(f\"Flattened X_train_flat shape: {X_train_flat.shape}\")\n",
        "print(f\"Flattened X_valid_flat shape: {X_valid_flat.shape}\")\n",
        "print(f\"Flattened X_test_flat shape: {X_test_flat.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bvB9LRGnKTc",
        "outputId": "dc9a05e3-77e0-42f1-8e8b-b2c8ff594d1b"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened X_train_flat shape: (312, 15)\n",
            "Flattened X_valid_flat shape: (101, 15)\n",
            "Flattened X_test_flat shape: (107, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "VR39O1Lj9xSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0581d4b6-55e5-4e0a-f640-54c060798189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Scores: 0.6237623762376238, 0.594059405940594, 0.46534653465346537\n",
            "Test Scores: 0.308411214953271, 0.29906542056074764, 0.2803738317757009\n"
          ]
        }
      ],
      "source": [
        "# 5. Model implementation\n",
        "# 1) Default SVM model (Support Vector Machine)\n",
        "from sklearn.svm import SVC\n",
        "model1 = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Train the model on the flattened training data\n",
        "model1.fit(X_train_flat, y_train_segments)\n",
        "\n",
        "# Evaluate on validation and test data\n",
        "validation_score1 = model1.score(X_valid_flat, y_valid_segments)\n",
        "test_score1 = model1.score(X_test_flat, y_test_segments)\n",
        "\n",
        "# 2) Random Forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the flattened training data\n",
        "model2.fit(X_train_flat, y_train_segments)\n",
        "\n",
        "# Evaluate on validation and test data\n",
        "validation_score2 = model2.score(X_valid_flat, y_valid_segments)\n",
        "test_score2 = model2.score(X_test_flat, y_test_segments)\n",
        "\n",
        "# 3) XGBoost (Gradient Boosting)\n",
        "import xgboost as xgb\n",
        "model3 = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the flattened training data\n",
        "model3.fit(X_train_flat, y_train_segments)\n",
        "\n",
        "# Evaluate on validation and test data\n",
        "validation_score3 = model3.score(X_valid_flat, y_valid_segments)\n",
        "test_score3 = model3.score(X_test_flat, y_test_segments)\n",
        "\n",
        "print(f\"Validation Scores: {validation_score1}, {validation_score2}, {validation_score3}\")\n",
        "print(f\"Test Scores: {test_score1}, {test_score2}, {test_score3}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 7 Conclusions\n",
        "\n",
        "Your conclusions, suggestions for improvements, etc should go here.\n",
        "\n",
        "**Limitations**\n",
        "- Lie is a story: Lie is easy\n",
        "- Errors:  Note that liars tend to wrap their lies with true\n",
        "information in an effort to be convincing (Peskov\n",
        "et al., 2020), i.e., lies are diluted by truth . <https://aclanthology.org/2021.emnlp-main.370.pdf>\n",
        "<https://www.tandfonline.com/doi/abs/10.1080/10683169908401767>\n",
        "- Othello error: Truth tellers might be as nervous as liars. But stakes in this type of story telling are lower, so the effect of the Othello error is smaller.\n",
        "\n",
        "- Consider: if we were to select a sample randomly we would have a 50% probability of being correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTcUkcuLhX91"
      },
      "source": [
        "# 8 References\n",
        "\n",
        "Acknowledge others here (books, papers, repositories, libraries, tools)\n",
        "- (Purushottam Gupta, 2024) <https://medium.com/@purushottamgupta2010/splitting-audio-files-into-manageable-segments-with-python-890aba53d254>\n",
        "- <http://lorien.die.upm.es/~lapiz/rtth/JORNADAS/VI/pdfs/0003.pdf>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KVNSfPMhX92"
      },
      "source": [
        "# FINAL CHECK- CHECK EVERYTHING DONE. VAMOOOOOOOOOOOOS YOU GOT IT!!- final check with you know who- vamos\n",
        "- Text cells contain: description in  own words, **rigorously** and **concisely**\n",
        "    1.  your approach\n",
        "    2. each implemented step\n",
        "    3. the results that you obtain"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}